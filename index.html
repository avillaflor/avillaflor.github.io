<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Adam Villaflor</title>
  
  <meta name="author" content="Adam Villaflor">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Adam Villaflor</name>
              </p>
              <p>I recently graduated with a PhD from the Robotics Institute at Carnegie Mellon University, where I had the good fortune to be co-advised by Professors <a href="https://www.cs.cmu.edu/~schneide/">Jeff Schneider</a> and <a href="https://www.ri.cmu.edu/ri-faculty/john-m-dolan/">John Dolan</a>.
              </p>
              <p>
              My research interests are focused on deep reinforcement learning, generative modeling, and deep learning for prediction and planning.
              I am excited about developing and deploying machine learning systems for real-world applications like autonomous driving.
              I received my Bachelor's and Master's at UC Berkeley, where I did research in reinforcement learning for robotics as part of Professors <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine's</a> and <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel's</a> group.
              </p>
              <p style="text-align:center">
                <a href="mailto:adamrvillaflor@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Vlfz-_IAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/adam-villaflor-3a8405104/">LinkedIn</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/AdamVillaflor.jpg"><img style="width:50%;max-width:50%" alt="profile photo" src="images/AdamVillaflor.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td width="15%">
              <img src="images/p2dbm.png" alt="p2dbm" width="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Tractable Joint Prediction and Planning Over Discrete Behavior Modes for Urban Driving</papertitle>
              <br>
              <strong>Adam Villaflor</strong>, Brian Yang, Huangyuan Su, Katerina Fragkiadaki, John Dolan, Jeff Schneider
              <br>
              <em>ICRA</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2403.07232">paper</a>
              / <a href="https://github.com/avillaflor/P2DBM">code</a>
            </td>
          </tr>
          <tr>
            <td width="15%">
              <img src="images/addressing_optimism.png" alt="p2dbm" width="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning</papertitle>
              <br>
              <strong>Adam Villaflor</strong>, Zhe Huang, Swapnil Pande, John Dolan, Jeff Schneider
              <br>
              <em>ICML</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2207.10295">paper</a>
              / <a href="https://github.com/avillaflor/SPLT-transformer">code</a>
            </td>
          </tr>
          <tr>
            <td width="15%" valign="middle">
                <img src='images/bats_stitching.png' width=160>
            </td>
            <td width="75%" valign="middle">
              <papertitle>BATS: Best Action Trajectory Stitching</papertitle>
              <br>
              Ian Char, Viraj Mehta, <strong>Adam Villaflor</strong>, John Dolan, Jeff Schneider
              <br>
              <em>NeurIPS Offline Reinforcement Learning Workshop</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2204.12026">paper</a>
            </td>
          </tr>
          <tr>
            <td width="15%" valign="middle">
                <img src='images/robustly_negotiate.png' width=160>
            </td>
            <td width="75%" valign="middle">
              <papertitle>Learning to Robustly Negotiate Bi-Directional Lane Usage in High-Conflict Driving Scenarios</papertitle>
              <br>
              Christoph Killing, <strong>Adam Villaflor</strong>, John Dolan
              <br>
              <em>ICRA</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2103.12070">paper</a>
            </td>
          </tr>
          <tr>
            <td width="15%" valign="middle">
                <img src='images/mb2po.png' width=160>
            </td>
            <td width="75%" valign="middle">
              <papertitle>Fine-Tuning Offline Reinforcement Learning with Model-Based Policy Optimization</papertitle>
              <br>
              <strong>Adam Villaflor</strong>, John Dolan, Jeff Schneider
              <br>
              <em>NeurIPS Offline Reinforcement Learning Workshop</em>, 2020
              <br>
              <a href="https://offline-rl-neurips.github.io/pdf/62.pdf">paper</a>
            </td>
          </tr>
          <tr>
            <td width="15%" valign="middle">
                <img src='images/iv2020.jpeg' width=160 height=160>
            </td>
            <td width="75%" valign="middle">
              <papertitle>Learning Highway Ramp Merging via Reinforcement Learning with Temporally-Extended Actions</papertitle>
              <br>
              Samuel Triest, <strong>Adam Villaflor</strong>, John Dolan
              <br>
              <em>IV</em>, 2020
              <br>
              <a href="https://ieeexplore.ieee.org/document/9304841">paper</a>
            </td>
          </tr>
          <tr>
            <td width="15%" valign="middle">
                <img src='images/caps.jpg' width=160 height=160>
            </td>
            <td width="75%" valign="middle">
              <papertitle>Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation</papertitle>
              <br>
              Gregory Kahn*, <strong>Adam Villaflor*</strong>, Pieter Abbeel, Sergey Levine
              <br>
              <em>CoRL</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1810.07167">paper</a>
              / <a href="https://github.com/gkahn13/CAPs">code</a>
            </td>
          </tr>
          <tr>
            <td width="15%" valign="middle">
                <img src='images/gcg.png' width=160 height=160>
            </td>
            <td width="75%" valign="middle">
              <papertitle>Self-supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation</papertitle>
              <br>
              Gregory Kahn, <strong>Adam Villaflor</strong>, Bosen Ding, Pieter Abbeel, Sergey Levine
              <br>
              <em>ICRA</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1709.10489">paper</a>
              / <a href="https://github.com/gkahn13/gcg">code</a>
            </td>
          </tr>
          <tr>
            <td width="15%" valign="middle">
                <img src='images/rccar_teaser_cone.jpg' width=160 height=160>
            </td>
            <td width="75%" valign="middle">
              <papertitle>Uncertainty-Aware Reinforcement Learning for Collision Avoidance</papertitle>
              <br>
              Gregory Kahn, <strong>Adam Villaflor</strong>, Vitchyr Pong, Pieter Abbeel, Sergey Levine
              <br>
              <em>arXiv</em>, 2017
              <br>
              <a href="https://arxiv.org/abs/1702.01182">paper</a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template taken from <a href="https://github.com/jonbarron/jonbarron_website">here</a>!
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
