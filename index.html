<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" >
<head>

<style type="text/css">
h1
{
margin-top: 0;
margin-bottom: 0;
}
h3
{
margin-top: 0;
margin-bottom: 0;
}
body
{
color: #000000;
background: #FFFFFF;
}
a:link { 
color: #264889;
}
a:visited { 
color: #264844;
}
a:hover { 
color: #74AFAD;
text-decoration: none;
}
a:active { 
color: #74AFAD;
}
</style>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31068812-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<script type="text/javascript">
  function recordOutboundLink(link, category, action) {
    _gat._getTrackerByName()._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100);
  }
</script>

    <title>Adam Villaflor</title>
</head>
<body>

<center>
<table>
<tr>
<td style="width: 840px" valign=top align=left>

<table cellpadding=5px>
<tr>
<!--
<td valign=top>

<img src="images/portrait.jpg" border=0 width=280/>

</td>
-->
<td align=left valign=top width=100%>
<a id="top"></a>
<h1>Adam Villaflor</h1>

<dl>
<!--
<dt><b>Email:</b></dt>
<dd><img border=0 src="images/hideit.png" height=19></dd>
-->
<dt><b>Resume</b> (December 2017):</dt>
<dd>[<a href="papers/avillaflor_resume.pdf" onClick="recordOutboundLink(this, 'Links', 'Resume');return false;">PDF</a>]</dd>

<dt><b>Github:</b></dt>
<dd><a href="https://github.com/avillaflor" onClick="recordOutboundLink(this, 'Links', 'github');return false;">https://github.com/avillaflor</a></dd>

</dl>

</td>
</tr>
</table>
<!--
I am a Ph.D. student in <a href="http://www.eecs.berkeley.edu/">EECS</a> at UC Berkeley advised by Professor <a href="http://www.cs.berkeley.edu/~pabbeel/">Pieter Abbeel</a> and Professor <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a> in the <a href="http://bair.berkeley.edu/">Berkeley Artificial Intelligence Research (BAIR)</a> Lab.

<p>
My main research goal is to develop algorithms that enable robots to operate in the real world. I am currently working on deep reinforcement learning. In the past, I have worked on trajectory optimization, planning under uncertainty, manipulation, and surgical robotics. 
</p>
-->

<table cellpadding=5px>

<tr>
<td valign=top align=left>
<img border=0 src="images/caps.jpg" width=150 height=148 />
</td>

<td valign=top align=left>
<b>
Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation
</b>
<br>
Gregory Kahn*, Adam Villaflor*, Pieter Abbeel, Sergey Levine
</br>
CoRL 2018.
[<a href="https://arxiv.org/pdf/1810.07167.pdf" onClick="recordOutboundLink(this, 'Links', 'caps_pdf');return false;">PDF</a>][<a href="https://youtu.be/lOLT7zifEkg" onClick="recordOutboundLink(this, 'Links', 'caps_video');return false;">Video</a>][<a href="https://github.com/gkahn13/CAPs" onClick="recordOutboundLink(this, 'Links', 'caps_blog');return false;">Code</a>]
<p>
We propose a framework that learns event cues from off-policy data, and can flexibly
combine these event cues at test time to accomplish different tasks. These event cue
labels are not assumed to be known a priori, but are instead labeled using learned
models, such as computer vision detectors, and then "backed up" in time using an
action-conditioned predictive model. We show that a simulated robotic car and a
real-world RC car can gather data and train fully autonomously without any human-provided
labels beyond those needed to train the detectors, and then at test-time be
able to accomplish a variety of different tasks.
</p>
</td>
</tr>

<tr>
<td valign=top align=left>
<img border=0 src="images/gcg.png" width=150 height=150 />
</td>

<td valign=top align=left>
<b>
Self-supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation
</b>
<br>
Gregory Kahn, Adam Villaflor, Bosen Ding, Pieter Abbeel, Sergey Levine
</br>
ICRA 2018.
[<a href="https://arxiv.org/pdf/1709.10489.pdf" onClick="recordOutboundLink(this, 'Links', 'gcg_pdf');return false;">PDF</a>][<a href="https://www.youtube.com/watch?v=vgiW0HlQWVE" onClick="recordOutboundLink(this, 'Links', 'gcg_video');return false;">Video</a>][<a href="https://github.com/gkahn13/gcg" onClick="recordOutboundLink(this, 'Links', 'gcg_web');return false;">Code</a>][<a href="https://drive.google.com/file/d/145sQOLpVAbAh1gotVSeNMNlWs3hqviCE/view?usp=sharing" onClick="recordOutboundLink(this, 'Links', 'gcg_poster');return false;">Poster</a>][<a href="https://drive.google.com/file/d/12QfxJVd6Q_4x9rWhB6KjP0LWRdX2nISs/view?usp=sharing" onClick="recordOutboundLink(this, 'Links', 'gcg_slides');return false;">Slides</a>]<p>
We propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, and instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and N-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training.
</p>
</td>
</tr>

<tr>
<td valign=top align=left>
<img border=0 src="images/rccar_teaser_cone.jpg" width=150 height=150 />
</td>

<td valign=top align=left>
<b>
Uncertainty-Aware Reinforcement Learning for Collision Avoidance
</b>
<br>
Gregory Kahn, Adam Villaflor, Vitchyr Pong, Pieter Abbeel, Sergey Levine
</br>
arXiv:1702.01182
[<a href="https://arxiv.org/pdf/1702.01182.pdf" onClick="recordOutboundLink(this, 'Links', 'probcoll_pdf');return false;">PDF</a>][<a href="https://sites.google.com/site/probcoll/" onClick="recordOutboundLink(this, 'Links', 'probcoll_web');return false;">Video</a>][<a href="https://www.dropbox.com/s/327ul2fqu1y8bkg/2017_probcoll.pptx?dl=0" onClick="recordOutboundLink(this, 'Links', 'plato_slides');return false;">Slides</a>]
<p>
Practical deployment of reinforcement learning methods must contend with the fact that the training process itself can be unsafe for the robot. In this paper, we consider the specific case of a mobile robot learning to navigate an a priori unknown environment while avoiding collisions. We present an uncertainty-aware model-based learning algorithm that estimates the probability of collision together with a statistical estimate of uncertainty. We evaluate our method on a simulated and real-world quadrotor, and a real-world RC car.
</p>
</td>
</tr>


</table>


</center>

</body>
</html>


